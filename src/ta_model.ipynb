{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPUx4UsgIRvbJTBU2h2j99m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nathsteve13/tugas-akhir/blob/main/src/ta_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiv__hRbDDvf",
        "outputId": "66243404-5d2b-48ab-985b-d4dfae27330e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import shutil, unicodedata\n",
        "from PIL import Image, UnidentifiedImageError"
      ],
      "metadata": {
        "id": "CB0xUNyvHETy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = \"/content/drive/MyDrive/dataset_babybrandedshop\"\n",
        "import os\n",
        "assert os.path.isdir(DATA_DIR), f\"Folder dataset tidak ditemukan: {DATA_DIR}\"\n",
        "print(\"OK. Dataset folder ditemukan:\", DATA_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2w3PXTaDtDz",
        "outputId": "3ec1cebc-d750-4e5d-c3cc-a255e233362f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK. Dataset folder ditemukan: /content/drive/MyDrive/dataset_babybrandedshop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import imghdr\n",
        "import os\n",
        "\n",
        "\n",
        "image_extensions = [\".png\", \".jpg\", \".jpeg\", \".gif\", \".bmp\", \".tif\", \".tiff\", \".webp\"]\n",
        "img_type_accepted_by_tf = [\"bmp\", \"gif\", \"jpeg\", \"png\"]\n",
        "\n",
        "count_checked = 0\n",
        "count_deleted = 0\n",
        "count_error = 0\n",
        "\n",
        "for filepath in Path(DATA_DIR).rglob(\"*\"):\n",
        "    if filepath.is_file() and filepath.suffix.lower() in image_extensions:\n",
        "        count_checked += 1\n",
        "        img_type = imghdr.what(filepath)\n",
        "\n",
        "        if img_type is None or img_type not in img_type_accepted_by_tf:\n",
        "            try:\n",
        "                os.remove(filepath)\n",
        "                print(f\"[DELETED] {filepath} ({img_type})\")\n",
        "                count_deleted += 1\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Gagal menghapus {filepath}: {e}\")\n",
        "                count_error += 1\n",
        "\n",
        "print(\"\\n✅ Selesai.\")\n",
        "print(f\"Total file dicek     : {count_checked}\")\n",
        "print(f\"Total file dihapus   : {count_deleted}\")\n",
        "print(f\"Total gagal dihapus  : {count_error}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "g95jzqgrWYTW",
        "outputId": "a65db872-2a20-4f3b-860f-2f25410739cd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1329616868.py:2: DeprecationWarning: 'imghdr' is deprecated and slated for removal in Python 3.13\n",
            "  import imghdr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Selesai.\n",
            "Total file dicek     : 3346\n",
            "Total file dihapus   : 0\n",
            "Total gagal dihapus  : 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "TF_SUPPORTED = {\".jpg\", \".jpeg\", \".png\", \".gif\", \".bmp\"}\n",
        "CONVERTIBLE  = {\".webp\", \".jfif\", \".tif\", \".tiff\"}\n",
        "data_path = Path(DATA_DIR)\n",
        "\n",
        "class_dirs = [p for p in data_path.iterdir() if p.is_dir()]\n",
        "class_names = sorted([p.name for p in class_dirs])\n",
        "\n",
        "print(f\"Jumlah kelas: {len(class_names)}\")\n",
        "print(\"Kelas:\", class_names)\n",
        "\n",
        "counts = {}\n",
        "total = 0\n",
        "for c in class_dirs:\n",
        "    n = sum(1 for f in c.rglob(\"*\") if f.suffix.lower() in TF_SUPPORTED)\n",
        "    counts[c.name] = n\n",
        "    total += n\n",
        "\n",
        "print(\"\\nRingkasan jumlah file per kelas:\")\n",
        "for k, v in counts.items():\n",
        "    print(f\"- {k}: {v}\")\n",
        "print(f\"\\nTotal gambar: {total}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nG40JOsnGc4x",
        "outputId": "76734f7c-186d-4961-c409-5795d5180369"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah kelas: 12\n",
            "Kelas: ['.ipynb_checkpoints', 'backpack', 'bottlepacifier', 'boy16y', 'boy36m', 'girl16y', 'girl36m', 'hat', 'shoes', 'socks', 'stroller', 'swimsuit']\n",
            "\n",
            "Ringkasan jumlah file per kelas:\n",
            "- swimsuit: 311\n",
            "- backpack: 303\n",
            "- socks: 350\n",
            "- hat: 300\n",
            "- stroller: 298\n",
            "- boy36m: 318\n",
            "- girl36m: 270\n",
            "- bottlepacifier: 299\n",
            "- boy16y: 332\n",
            "- girl16y: 250\n",
            "- shoes: 315\n",
            "- .ipynb_checkpoints: 0\n",
            "\n",
            "Total gambar: 3346\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE   = (256, 256)\n",
        "BATCH_SIZE = 32\n",
        "VAL_SPLIT  = 0.2\n",
        "SEED       = 42\n",
        "AUTOTUNE   = tf.data.AUTOTUNE"
      ],
      "metadata": {
        "id": "tcyFE-TWGmvi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess = keras.Sequential([\n",
        "    layers.Resizing(IMG_SIZE[0], IMG_SIZE[1]),\n",
        "    layers.Rescaling(1./255),\n",
        "], name=\"preprocess\")\n",
        "\n",
        "augment = keras.Sequential([\n",
        "    layers.RandomFlip(mode=\"horizontal_and_vertical\"),\n",
        "    layers.RandomRotation(factor=0.0833, fill_mode=\"reflect\"),\n",
        "    layers.RandomZoom(height_factor=(-0.10, 0.10), width_factor=(-0.10, 0.10)),\n",
        "    layers.RandomContrast(factor=0.2),\n",
        "    layers.RandomBrightness(factor=0.1),\n",
        "], name=\"augment\")\n"
      ],
      "metadata": {
        "id": "cOisNzrKHre5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = keras.preprocessing.image_dataset_from_directory(\n",
        "    str(DATA_DIR),\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    validation_split=VAL_SPLIT,\n",
        "    subset=\"training\",\n",
        "    seed=SEED,\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        ")\n",
        "\n",
        "val_ds = keras.preprocessing.image_dataset_from_directory(\n",
        "    str(DATA_DIR),\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    validation_split=VAL_SPLIT,\n",
        "    subset=\"validation\",\n",
        "    seed=SEED,\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        ")\n",
        "class_names = train_ds.class_names\n",
        "num_classes = len(class_names)\n",
        "print(\"Kelas:\", class_names, \"| num_classes:\", num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiDOunTDHvfq",
        "outputId": "dd80605c-a3cf-41d3-92dc-202613d175e9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3346 files belonging to 11 classes.\n",
            "Using 2677 files for training.\n",
            "Found 3346 files belonging to 11 classes.\n",
            "Using 669 files for validation.\n",
            "Kelas: ['backpack', 'bottlepacifier', 'boy16y', 'boy36m', 'girl16y', 'girl36m', 'hat', 'shoes', 'socks', 'stroller', 'swimsuit'] | num_classes: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = (\n",
        "    train_ds\n",
        "    .map(lambda x, y: (augment(x, training=True), y), num_parallel_calls=AUTOTUNE)\n",
        "    .map(lambda x, y: (preprocess(x), y), num_parallel_calls=AUTOTUNE)\n",
        "    .cache()\n",
        "    .shuffle(1000)\n",
        "    .prefetch(buffer_size=AUTOTUNE)\n",
        ")\n",
        "\n",
        "val_ds = (\n",
        "    val_ds\n",
        "    .map(lambda x, y: (preprocess(x), y), num_parallel_calls=AUTOTUNE)\n",
        "    .cache()\n",
        "    .prefetch(buffer_size=AUTOTUNE)\n",
        ")\n"
      ],
      "metadata": {
        "id": "uIs8mcXLat2E"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "for images, labels in train_ds.take(1):\n",
        "    print(\"Bentuk gambar:\", images.shape)\n",
        "    print(\"Bentuk label:\", labels.shape)\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy())\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        class_index = np.argmax(labels[i].numpy())\n",
        "        plt.title(class_names[class_index])\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "ruGEXSCHLuym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SHAPE = (256, 256, 3)\n",
        "NUM_CLASSES = 11\n",
        "LR = 1e-6"
      ],
      "metadata": {
        "id": "hj0-jLXya0xO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== 1) Encoder–Decoder (CAE) ======\n",
        "def build_cae(img_shape=IMG_SHAPE):\n",
        "    He = keras.initializers.HeNormal()\n",
        "\n",
        "    def conv_bn_relu(x, filters, k=3):\n",
        "        x = layers.Conv2D(filters, k, padding=\"same\", use_bias=False, kernel_initializer=He)(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.ReLU()(x)\n",
        "        return x\n",
        "\n",
        "    def deconv_bn_relu(x, filters, k=3, s=2):\n",
        "        x = layers.Conv2DTranspose(filters, k, strides=s, padding=\"same\", use_bias=False, kernel_initializer=He)(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.ReLU()(x)\n",
        "        return x\n",
        "\n",
        "    inp = keras.Input(shape=img_shape)\n",
        "\n",
        "    # ----- ENCODER: 32 -> 64 -> 128 -----\n",
        "    x = conv_bn_relu(inp, 32)                 # 256x256x32\n",
        "    x = layers.MaxPool2D(pool_size=2)(x)      # 128x128\n",
        "\n",
        "    x = conv_bn_relu(x, 64)                   # 128x128x64\n",
        "    x = layers.MaxPool2D(pool_size=2)(x)      # 64x64\n",
        "\n",
        "    x = conv_bn_relu(x, 128)                  # 64x64x128\n",
        "    bottleneck = layers.MaxPool2D(pool_size=2, name=\"bottleneck\")(x)   # 32x32x128\n",
        "\n",
        "    # ----- DECODER (simetris) -----\n",
        "    y = deconv_bn_relu(bottleneck, 128, k=3, s=2)   # 64x64x128\n",
        "    y = conv_bn_relu(y, 128)\n",
        "\n",
        "    y = deconv_bn_relu(y, 64, k=3, s=2)             # 128x128x64\n",
        "    y = conv_bn_relu(y, 64)\n",
        "\n",
        "    y = deconv_bn_relu(y, 32, k=3, s=2)             # 256x256x32\n",
        "    y = conv_bn_relu(y, 32)\n",
        "\n",
        "    out = layers.Conv2D(3, 3, padding=\"same\", activation=\"sigmoid\", name=\"reconstruction\")(y)\n",
        "\n",
        "    cae = keras.Model(inp, out, name=\"CAE\")\n",
        "    encoder = keras.Model(inp, bottleneck, name=\"CAE_encoder\")\n",
        "    return cae, encoder\n",
        "\n",
        "cae, encoder = build_cae()\n"
      ],
      "metadata": {
        "id": "cxFgETV0gJoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== 2) Compile CAE (Eq. 2.13: MSE) ======\n",
        "cae.compile(optimizer=keras.optimizers.Adam(LR),\n",
        "            loss=\"mse\",\n",
        "            metrics=[keras.metrics.MeanAbsoluteError(name=\"mae\")])"
      ],
      "metadata": {
        "id": "f_OOAFp0gi6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== 3) Siapkan dataset AE: (x, x) ======\n",
        "def to_ae_pairs(x, y):\n",
        "    return x, x"
      ],
      "metadata": {
        "id": "351hJ13igkJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "cae_train = train_ds.map(to_ae_pairs, num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n",
        "cae_val   = val_ds.map(to_ae_pairs,   num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)"
      ],
      "metadata": {
        "id": "qxPBey0Ggmam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== 4) Pre-train CAE ======\n",
        "callbacks_ae = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\", patience=8, restore_best_weights=True, verbose=1\n",
        "    ),\n",
        "    keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor=\"val_loss\", factor=0.5, patience=4, min_lr=LR, verbose=1\n",
        "    ),\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"cae_best.weights.h5\",\n",
        "        monitor=\"val_loss\",\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    keras.callbacks.CSVLogger(\"cae_train_log.csv\", append=False),\n",
        "]\n",
        "history_ae = cae.fit(\n",
        "    cae_train,\n",
        "    validation_data=cae_val,\n",
        "    epochs=100,\n",
        "    callbacks=callbacks_ae,\n",
        "    verbose=1\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "nqoF9cFsgqck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== 5) CNN Classifier di atas BOTTLENECK ======\n",
        "def build_classifier(encoder_model, num_classes=NUM_CLASSES, use_augment=True):\n",
        "    encoder_model.trainable = False  # stage-1: freeze\n",
        "\n",
        "    augment = keras.Sequential([\n",
        "        layers.RandomFlip(mode=\"horizontal_and_vertical\"),\n",
        "        layers.RandomRotation(factor=0.0833, fill_mode=\"reflect\"),\n",
        "        layers.RandomZoom(height_factor=(-0.10, 0.10), width_factor=(-0.10, 0.10)),\n",
        "        layers.RandomContrast(factor=0.2),\n",
        "        layers.RandomBrightness(factor=0.1),\n",
        "    ], name=\"augment\") if use_augment else keras.Sequential(name=\"no_augment\")\n",
        "\n",
        "    He = keras.initializers.HeNormal()\n",
        "\n",
        "    def conv_bn_relu(x, f, k=3):\n",
        "        x = layers.Conv2D(f, k, padding=\"same\", use_bias=False, kernel_initializer=He)(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.ReLU()(x)\n",
        "        return x\n",
        "\n",
        "    inp = keras.Input(shape=IMG_SHAPE, name=\"clf_input\")\n",
        "    x = augment(inp)\n",
        "    z = encoder_model(x)                       # 32x32x128 (dari CAE)\n",
        "\n",
        "    x = conv_bn_relu(z, 128)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    x = layers.Dense(256, activation=\"relu\", kernel_initializer=He)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    out = layers.Dense(num_classes, activation=\"softmax\", name=\"clf_output\")(x)\n",
        "\n",
        "    return keras.Model(inp, out, name=\"Hybrid_CAE_CNN\")\n",
        "\n",
        "clf = build_classifier(encoder)\n"
      ],
      "metadata": {
        "id": "czRryWxajW6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== 6) Compile classifier (Eq. 2.14: Cross-Entropy) ======\n",
        "clf.compile(optimizer=keras.optimizers.Adam(LR),\n",
        "            loss=\"categorical_crossentropy\",\n",
        "            metrics=[\"accuracy\"])\n",
        "\n",
        "# Dataset untuk klasifikasi: gunakan (x, y) asli (bukan (x, x))\n",
        "clf_train = train_ds.prefetch(AUTOTUNE)\n",
        "clf_val   = val_ds.prefetch(AUTOTUNE)"
      ],
      "metadata": {
        "id": "Pof799tTjjZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== 8) Fine-tune tahap-2 (unfreeze sebagian encoder) ======\n",
        "# Buka blok terakhir encoder agar representasi menyesuaikan task\n",
        "for layer in encoder.layers[-4:]:   # sesuaikan kedalaman pembukaan\n",
        "    layer.trainable = True\n",
        "\n",
        "clf.compile(optimizer=keras.optimizers.Adam(LR),  # LR lebih kecil\n",
        "            loss=\"categorical_crossentropy\",\n",
        "            metrics=[\"accuracy\"])\n",
        "\n",
        "callbacks_clf_stage2 = [\n",
        "    keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=6, restore_best_weights=True),\n",
        "    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=LR),\n",
        "    keras.callbacks.ModelCheckpoint(\"hybrid_finetuned.keras\", save_best_only=True, monitor=\"val_accuracy\"),\n",
        "]\n",
        "history_clf_stage2 = clf.fit(clf_train, validation_data=clf_val, epochs=20, callbacks=callbacks_clf_stage2)"
      ],
      "metadata": {
        "id": "PJB8qoYLmwk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_metrics = clf.evaluate(clf_val, verbose=0)\n",
        "print(dict(zip(clf.metrics_names, final_metrics)))"
      ],
      "metadata": {
        "id": "bdJjsFV7m2e2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Initialize lists to store true and predicted labels\n",
        "y_true, y_pred = [], []\n",
        "\n",
        "# Iterate over the validation dataset\n",
        "for x_batch, y_batch in clf_val:\n",
        "    # Get predictions for the current batch\n",
        "    p = clf.predict(x_batch, verbose=0)\n",
        "\n",
        "    # Convert one-hot encoded labels to class indices\n",
        "    y_true.extend(np.argmax(y_batch.numpy(), axis=1))\n",
        "    y_pred.extend(np.argmax(p, axis=1))\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "y_true = np.array(y_true)\n",
        "y_pred = np.array(y_pred)\n",
        "\n",
        "# Calculate and print the confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "# Generate and print the classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=class_names, digits=4))"
      ],
      "metadata": {
        "id": "OLJglUBenNXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_history(h, keys=(\"loss\",\"val_loss\")):\n",
        "    plt.figure()\n",
        "    for k in keys: plt.plot(h.history[k], label=k)\n",
        "    plt.legend(); plt.xlabel(\"Epoch\"); plt.grid(True)\n",
        "\n",
        "# CAE (rekonstruksi)\n",
        "plot_history(history_ae, (\"loss\",\"val_loss\"))\n",
        "\n",
        "# CNN stage-1 (head frozen)\n",
        "plot_history(history_clf_stage1, (\"loss\",\"val_loss\"))\n",
        "plot_history(history_clf_stage1, (\"accuracy\",\"val_accuracy\"))\n",
        "\n",
        "# CNN stage-2 (unfreeze sebagian)\n",
        "plot_history(history_clf_stage2, (\"loss\",\"val_loss\"))\n",
        "plot_history(history_clf_stage2, (\"accuracy\",\"val_accuracy\"))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wFl7KCa6nV5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Create the 'models' directory if it doesn't exist\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "\n",
        "# simpan model classifier final (struktur+weights)\n",
        "clf.save(\"models/hybrid_classifier_savedmodel.keras\")\n",
        "\n",
        "# simpan encoder (untuk reuse / feature extractor)\n",
        "encoder.save(\"models/encoder_savedmodel.keras\")\n",
        "\n",
        "# simpan CAE terbaik (optional untuk bab rekonstruksi)\n",
        "# (jika kamu menyimpan checkpoint CAE sebelumnya)\n",
        "# tf.keras.models.load_model(\"cae_best.keras\").save(\"models/cae_savedmodel.keras\")"
      ],
      "metadata": {
        "id": "59y7OK6XnaxH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}